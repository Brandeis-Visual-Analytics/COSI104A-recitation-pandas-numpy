{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212e8942-cde2-4476-b2d1-fc024ce49080",
   "metadata": {},
   "source": [
    "# Recitation 2: Numpy and Pandas\n",
    "\n",
    "In this recitation, you went through tutorials for two of the most important python packages for machine learning and data science at large: `numpy` and `pandas`.\n",
    "\n",
    "In this notebook, I'll ask you to download a dataset into a `pandas` DataFrame, and then execute some transformations on the data both with `pandas` and with `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cbd1f-a53d-4da3-aa7f-f486fc2aee25",
   "metadata": {},
   "source": [
    "## Step 1: Download and format the data.\n",
    "\n",
    "We are going to start by using `pandas` to download a weather dataset from the National Oceanic and Atmospheric Administration (NOAA), a U.S. federal agency that studies climate phenomena and publishes a wealth of open climate data.  This dataset contains the average temperature, in degrees Fahrenheit, of the [continental United States](https://www.ncei.noaa.gov/access/monitoring/dyk/us-climate-divisions) measured in January of each year from 1895 to 2025.\n",
    "\n",
    "Stepping through the code, first we import the `pandas` library and store it in a variable called `pd`.  When you run this cell, this makes `pandas` available in that variable `pd` in *all cells* in this notebook.  Usually we import libraries and define variables towards the top of a Jupyter notebook, so that they are available in the cells towards the bottom.\n",
    "\n",
    "Next, we pass a URL that points to the data (held in a `.csv` file, which stands for Comma-Separated Values) in to the `read_csv` function from the `pandas` library.  The `read_csv` function is very powerful: it downloads the data, automatically separates the fields, and loads them into an object called a DataFrame, which is a rich class representing a dataset.  DataFrames have many convenience methods, which you can try out yourself in the subsequent cells.  We use a simple one, `head()`, which returns the top 5 rows of a dataset.  This is very frequently done to do a \"sanity check\", i.e. to make sure the dataset is in the format you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860e640-d717-4e08-8f52-dd18bfaf67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This URL points to the NOAA data on average temperature in the US in the month of January from 1895 to 2025.\n",
    "url = \"https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/national/time-series/110/tavg/1/1/1895-2025/data.csv\"\n",
    "\n",
    "# We skip the first 2 rows because pandas can't parse the comments at the top of the file.\n",
    "df = pd.read_csv(url, skiprows=2)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa6e80-9439-4c85-8ce1-58374d2c52ef",
   "metadata": {},
   "source": [
    "This data looks ok, but the date field won't be particularly useful to us if we are doing machine learning.  While it's numeric, we would like it to be scaled to be more meaningful, rather than including the month, i.e. `1895` would be more useful than `189501`.  To do this, we are going to use a `pandas` function to first convert that date string into a Date object, then extract the year itself from the Date object.  Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a3da2-acd9-4d50-a56b-23b1de31aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Formatted-Date'] = pd.to_datetime(df['Date'], format='%Y%m')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6baa04-4bc3-4659-8063-be76fc9a83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['Formatted-Date'].dt.year\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11514c38-2dcd-4de7-80f8-4d972b13e377",
   "metadata": {},
   "source": [
    "To extract the year as a new column, first we used a `pandas` method `to_datetime`.  This method takes in a collection of strings (either a full DataFrame, or a single column, known as a Series, which is what we did here).  By default, it tries to parse the date, but you typically need to provide it a format string, which tells the parser what format the date is in.  Here, we passed in `%Y%m`, which means a 4-digit year immediately followed by a 2-digit month.  After that, we print out the head of the dataframe and see that the Formatted-Date column contains a full date (1895-01-01), rather than the awkward date string(189501).\n",
    "\n",
    "Next, we create a new column which extracts the year from those date objects.  This time, we call `.dt` on our Formatted-Date column, which returns the values as DateTime objects, which have accessors for things like the year, month, or day.\n",
    "\n",
    "--------\n",
    "\n",
    "Next, I want you to try to update this DataFrame in two ways.  First, I want you to update the name of the `Value` feature to be `degrees-fahr`.  Then, I want you to create a new column that represents `degrees-cent`, i.e. the temperature in Celsius.  There are many ways to update the name: you could [try the `df.rename(.)` function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html), for example.  To create the new column with the temperature in Celsius, try to look up how to assign a new column based on existing columns - StackOverflow might be helpful here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a6c95-e41b-47bf-87a8-a0d13260e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcdf8d7-a189-45bc-a4be-ad75b1b8393b",
   "metadata": {},
   "source": [
    "## Step 2: Convert to numpy\n",
    "\n",
    "`pandas` is a nice library for formatting and transforming data.  It could be considered a \"heavy\" interface to the data - once you put your data into a DataFrame object, it has lots of functionality.  \n",
    "\n",
    "`numpy` is a library that can also transform data, but it more directly operates on numerical matrices - i.e. it doesn't do well with nonnumeric columns, like the Date column in our dataset.\n",
    "\n",
    "`pandas` and `numpy` datasets can convert from one to the other.  Here, we first drop the nonnumeric columns from our dataset (we don't need them anymore), and then we convert our DataFrame object into a `numpy` `ndarray`, a numpy object that stands for \"n-dimensional array\", another word for a matrix.  The method `df.values` converts the DataFrame object into a `numpy` `ndarray` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c316a3-879f-4fbb-8101-420c5ad0610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "numeric_df = df.drop(columns=[\"Date\", \"Formatted-Date\"])\n",
    "arr = numeric_df.values\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991086c-355e-4ced-b775-b1a34ef4bd89",
   "metadata": {},
   "source": [
    "`numpy` has some nice features that make it easy to manipulate data - in class we used it to very quickly slice the data into a `trainX`, `trainY`, `testX`, and `testY`.  For now, we are just going to do some simple matrix multiplication.  Here, we define a weight vector `w`, and then do a matrix multiplication of our dataset, `arr`, with our weight vector, `w`.  However, `w` is likely not the correct length.  You want to define a weight for each column of your matrix `arr`.  Add some arbitrary values into `w` until the matrix multiplication at the end of the cell is able to complete.  [Note that `np.dot` is the `numpy` method for matrix multiplication, not just dot products.](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)\n",
    "\n",
    "Try out some different weights and see how your values change.  Consider that this is what a machine learning algorithm is doing - trying out different values of parameters to see how they affect the answer.\n",
    "\n",
    "Try out a few values for `w` and then you can consider this lab complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dde40-7266-45dd-9419-41679e270660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VALUES TO SEE HOW THE RESULT CHANGES\n",
    "w = np.array([1, 2, -2])  # HOW MANY \n",
    "\n",
    "result = np.dot(arr, w)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632fd18-02cb-4a02-ba3d-78c5e5e8d381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
